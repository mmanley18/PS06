---
title: "STAT/MATH 495: Problem Set 06"
author: "Meredith Manley"
date: "2017-10-17"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
```





# Collaboration

Please indicate who you collaborated with on this assignment: 





# Setup

Define truth, which again we know for the purposes of this assignment, but in
practice we won't:

* the true function f(x) i.e. the signal
* the true epsilon i.e. the noise, which in this case is Normal$(0, sd=\sigma)$.
Hence the standard deviation $\sigma$ determines the amount of noise.

```{r}
f <- function(x) {
  x^2
}
sigma <- 0.3
```

This is the target point we'll be trying to predict: $(0.95, f(0.95)) = (0.95, 0.95^2) = (0.95, 0.9025)$, Thus, the test set is just `x=0.95`

```{r}
x0 <- 0.95
test_set <- data_frame(x=x0)
```

This function generates a random sample of size $n$; think of this as a "get new
data" function. Random in terms of both:

* (New) the predictor x (uniform on [0,1])
* the amount of noise $\epsilon$

```{r}
generate_sample <- function(f, n, sigma) {
  sample <- data_frame(
    x = runif(n = n, min = 0, max = 1),
    f_x = f(x),
    epsilon = rnorm(n = n, mean = 0, sd = sigma),
    y = f_x + epsilon
  )
  # Recall: We don't observe f(x) and epsilon, just (x, y)
  sample <- sample %>% 
    select(x, y)
  
  return(sample)
}
```

Define

* The number $n$ of observations $(x_i, y_i)$ in each sample. In the handout,
$n=100$ to keep plots uncrowded. Here we boost to $n=500$
* Number of samples of size $n$ to consider

```{r}
n <- 500
n_sample <- 10000
```


# Computation


### Spline Model df=2
```{r}
MSE_list2 <- c()

Var_list2 <- c()

Bias_list2 <- c()

# dataset of true value
true_y <- rep(0.95^2, 500)

for(i in 1:10000) {
  sampled_points <- generate_sample(f, n, sigma)

  # Fit splines with df=2 and add to plot
  model1 <- smooth.spline(x=sampled_points$x, y=sampled_points$y, df=2) 
  
  # Predictions
  y_hat <- predict(model1, newdata=test_set) %>% 
  tibble::as.tibble()
  y_hat <- y_hat$y
  
  # MSE and RMSE
  MSE <- mean((true_y - y_hat)^2)
  RMSE <- sqrt(MSE)
  
  MSE_list2[length(MSE_list2)+1] = MSE
  
  # Bias
  bias_sqr <- (mean(true_y - y_hat))^2
  
  Bias_list2[length(Bias_list2)+1] = bias_sqr
  
  # Variance
  variance <- var(y_hat)
  
  Var_list2[length(Var_list2)+1] = variance
}

# Sigma-Squared
sigma_sqr <- (sigma)^2

MSE_final <- mean(MSE_list2)
Bias <- mean(Bias_list2)
Var <- mean(Var_list2)
sigma_sqr <- (sigma)^2

Total <- Bias + Var + sigma_sqr

table <- matrix(c(MSE_final, Bias, Var, sigma_sqr, Total),ncol=5,byrow=TRUE)
colnames(table) <- c("MSE","Bias-Squared","Variance", "Irreducible", "Sum")
rownames(table) <- c("X")
table <- as.table(table)
table

```



### Spline Model df=99
```{r}
MSE_list99 <- c()

Var_list99 <- c()

Bias_list99 <- c()

# dataset of true value
true_y <- rep(0.95^2, 500)

for(i in 1:10000) {
  sampled_points <- generate_sample(f, n, sigma)

  # Fit splines with df=2 and add to plot
  model1 <- smooth.spline(x=sampled_points$x, y=sampled_points$y, df=99) 
  
  # Predictions
  y_hat <- predict(model1, newdata=test_set) %>% 
  tibble::as.tibble()
  y_hat <- y_hat$y
  
  # MSE and RMSE
  MSE <- mean((true_y - y_hat)^2)
  RMSE <- sqrt(MSE)
  
  MSE_list99[length(MSE_list99)+1] = MSE
  
  # Bias
  bias_sqr <- (mean(true_y - y_hat))^2
  
  Bias_list99[length(Bias_list99)+1] = bias_sqr
  
  # Variance
  variance <- var(y_hat)
  
  Var_list99[length(Var_list99)+1] = variance
}

# Sigma-Squared
sigma_sqr <- (sigma)^2

MSE_final <- mean(MSE_list99)
Bias <- mean(Bias_list99)
Var <- mean(Var_list99)
sigma_sqr <- (sigma)^2

Total <- Bias + Var + sigma_sqr

table <- matrix(c(MSE_final, Bias, Var, sigma_sqr, Total),ncol=5,byrow=TRUE)
colnames(table) <- c("MSE","Bias-Squared","Variance", "Irreducible", "Sum")
rownames(table) <- c("X")
table <- as.table(table)
table

```


# Tables

As done in Lec 2.7, for both

* An `lm` regression AKA a `smooth.splines(x, y, df=2)` model fit 
* A `smooth.splines(x, y, df=99)` model fit 

output tables comparing:

|  MSE| bias_squared|   var| irreducible|   sum|
|----:|------------:|-----:|-----------:|-----:|
|     X|           X  |     X |    X |          |


where `sum = bias_squared + var + irreducible`. You can created cleanly formatted tables like the one above by piping a data frame into `knitr::kable(digits=4)`.




# Analysis

**Questions**:

1. Based on the topics covered in Lec 2.7, name one possible "sanity check" for your results. Name another if you can.
1. In **two** sentences or less, give a rough sketch of what the procedure would
be to get the breakdown of $$\mbox{MSE}\left[\widehat{f}(x)\right]$$ for *all*
$x$ in this example, and not just for $$\mbox{MSE}\left[\widehat{f}(x_0)\right]
= \mbox{MSE}\left[\widehat{f}(0.95)\right]$$.
1. Which of the two models would you choose for predicting the point of interest and why?

**Answers**:

1. One possible sanity check would be to test your model on new data or your whole training dataset and see if it is accurate in its predictions.
1. If we wanted to get the breakdown of $\mbox{MSE}\left[\widehat{f}(x)\right]$ for *all*
$x$ in this example, and not just for $$\mbox{MSE}\left[\widehat{f}(x_0)\right]
= \mbox{MSE}\left[\widehat{f}(0.95)\right]$$ then we would need to do the procedure above, but for each $x$ in the training dataset from 1:500 rather than just 0.95.
1. I would choose the model with the df=99 because over time on average the model does well in predicting the outcome. Evidence of the law of large numbers.
